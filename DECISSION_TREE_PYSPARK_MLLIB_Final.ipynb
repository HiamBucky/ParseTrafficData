{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\spark-2.4.5-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- DAY: string (nullable = true)\n",
      " |-- STORES: string (nullable = true)\n",
      " |-- CONGESTION: integer (nullable = true)\n",
      " |-- OSM_ID: integer (nullable = true)\n",
      " |-- LARGER_THAN_200M: string (nullable = true)\n",
      " |-- KMH: integer (nullable = true)\n",
      " |-- CATEGORY: string (nullable = true)\n",
      " |-- HOUR: integer (nullable = true)\n",
      " |-- MIN: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('ml-bank').getOrCreate()\n",
    "df = spark.read.csv('PYSPARK_DATA_TRAFFIC.csv', header = True, inferSchema = True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>DAY</th>\n",
       "      <td>MONDAY</td>\n",
       "      <td>MONDAY</td>\n",
       "      <td>TUESDAY</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "      <td>WEDNESDAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STORES</th>\n",
       "      <td>OPEN</td>\n",
       "      <td>CLOSED</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>OPEN</td>\n",
       "      <td>CLOSED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONGESTION</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OSM_ID</th>\n",
       "      <td>176665188</td>\n",
       "      <td>176665188</td>\n",
       "      <td>176665188</td>\n",
       "      <td>176665188</td>\n",
       "      <td>176665188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LARGER_THAN_200M</th>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KMH</th>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CATEGORY</th>\n",
       "      <td>KA_1K</td>\n",
       "      <td>KA_1K</td>\n",
       "      <td>KA_1K</td>\n",
       "      <td>KA_1K</td>\n",
       "      <td>KA_1K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HOUR</th>\n",
       "      <td>17</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MIN</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          0          1          2          3          4\n",
       "DAY               MONDAY     MONDAY     TUESDAY    WEDNESDAY  WEDNESDAY\n",
       "STORES                 OPEN     CLOSED       OPEN       OPEN     CLOSED\n",
       "CONGESTION                0          0          0          0          0\n",
       "OSM_ID            176665188  176665188  176665188  176665188  176665188\n",
       "LARGER_THAN_200M        YES        YES        YES        YES        YES\n",
       "KMH                      50         50         50         50         50\n",
       "CATEGORY              KA_1K      KA_1K      KA_1K      KA_1K      KA_1K\n",
       "HOUR                     17         22         18         14         20\n",
       "MIN                      15          0         30         30         45"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(df.take(5), columns=df.columns).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------+----------+---------+----------------+---+--------+----+---+-----+--------+------------------+----------+--------+------+-----+-----+\n",
      "|      DAY| STORES|CONGESTION|   OSM_ID|LARGER_THAN_200M|KMH|CATEGORY|HOUR|MIN|MIN_n|OSM_ID_n|LARGER_THAN_200M_n|CATEGORY_n|STORES_n|HOUR_n|DAY_n|KMH_n|\n",
      "+---------+-------+----------+---------+----------------+---+--------+----+---+-----+--------+------------------+----------+--------+------+-----+-----+\n",
      "|MONDAY   |   OPEN|         0|176665188|             YES| 50|   KA_1K|  17| 15|  0.0|     0.0|               1.0|       1.0|     1.0|   3.0|  6.0|  1.0|\n",
      "|MONDAY   | CLOSED|         0|176665188|             YES| 50|   KA_1K|  22|  0|  1.0|     0.0|               1.0|       1.0|     0.0|   6.0|  6.0|  1.0|\n",
      "|TUESDAY  |   OPEN|         0|176665188|             YES| 50|   KA_1K|  18| 30|  2.0|     0.0|               1.0|       1.0|     1.0|  13.0|  5.0|  1.0|\n",
      "|WEDNESDAY|   OPEN|         0|176665188|             YES| 50|   KA_1K|  14| 30|  2.0|     0.0|               1.0|       1.0|     1.0|  10.0|  1.0|  1.0|\n",
      "|WEDNESDAY| CLOSED|         0|176665188|             YES| 50|   KA_1K|  20| 45|  3.0|     0.0|               1.0|       1.0|     0.0|   5.0|  1.0|  1.0|\n",
      "|WEDNESDAY|CLOSING|         0|176665188|             YES| 50|   KA_1K|  18|  0|  1.0|     0.0|               1.0|       1.0|     2.0|  13.0|  1.0|  1.0|\n",
      "|WEDNESDAY|   OPEN|         0|176665188|             YES| 50|   KA_1K|  17|  0|  1.0|     0.0|               1.0|       1.0|     1.0|   3.0|  1.0|  1.0|\n",
      "|FRIDAY   |   OPEN|         1|176665188|             YES| 50|   KA_1K|  12|  0|  1.0|     0.0|               1.0|       1.0|     1.0|   8.0|  0.0|  1.0|\n",
      "|THURSDAY |CLOSING|         1|176665188|             YES| 50|   KA_1K|  21| 15|  0.0|     0.0|               1.0|       1.0|     2.0|   1.0|  2.0|  1.0|\n",
      "|SUNDAY   | CLOSED|         1|176665188|             YES| 50|   KA_1K|  22| 15|  0.0|     0.0|               1.0|       1.0|     0.0|   6.0|  4.0|  1.0|\n",
      "|MONDAY   | CLOSED|         0|176665188|             YES| 50|   KA_1K|   1|  0|  1.0|     0.0|               1.0|       1.0|     0.0|   4.0|  6.0|  1.0|\n",
      "|MONDAY   | CLOSED|         0|176665188|             YES| 50|   KA_1K|   1| 30|  2.0|     0.0|               1.0|       1.0|     0.0|   4.0|  6.0|  1.0|\n",
      "|MONDAY   |   OPEN|         1|176665188|             YES| 50|   KA_1K|  15| 15|  0.0|     0.0|               1.0|       1.0|     1.0|  11.0|  6.0|  1.0|\n",
      "|WEDNESDAY| CLOSED|         0|176665188|             YES| 50|   KA_1K|   0| 45|  3.0|     0.0|               1.0|       1.0|     0.0|   2.0|  1.0|  1.0|\n",
      "|WEDNESDAY| CLOSED|         0|176665188|             YES| 50|   KA_1K|   1| 30|  2.0|     0.0|               1.0|       1.0|     0.0|   4.0|  1.0|  1.0|\n",
      "|WEDNESDAY|   OPEN|         0|176665188|             YES| 50|   KA_1K|  12|  0|  1.0|     0.0|               1.0|       1.0|     1.0|   8.0|  1.0|  1.0|\n",
      "|WEDNESDAY| CLOSED|         0|176665188|             YES| 50|   KA_1K|  19| 45|  3.0|     0.0|               1.0|       1.0|     0.0|  15.0|  1.0|  1.0|\n",
      "|WEDNESDAY| CLOSED|         1|176665188|             YES| 50|   KA_1K|  21| 45|  3.0|     0.0|               1.0|       1.0|     0.0|   1.0|  1.0|  1.0|\n",
      "|WEDNESDAY| CLOSED|         0|176665188|             YES| 50|   KA_1K|  23| 15|  0.0|     0.0|               1.0|       1.0|     0.0|   9.0|  1.0|  1.0|\n",
      "|WEDNESDAY| CLOSED|         0|176665188|             YES| 50|   KA_1K|  23| 45|  3.0|     0.0|               1.0|       1.0|     0.0|   9.0|  1.0|  1.0|\n",
      "+---------+-------+----------+---------+----------------+---+--------+----+---+-----+--------+------------------+----------+--------+------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column+\"_n\").fit(df) for column in list(set(df.columns)-set(['CONGESTION'])) ]\n",
    "pipeline = Pipeline(stages=indexers)\n",
    "df_r = pipeline.fit(df).transform(df)\n",
    "df_r.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_r.toPandas().to_csv(\"Spark_num_and_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_r.drop('HOUR','MIN','DAY','STORES','OSM_ID','LARGER_THAN_200M','KMH','CATEGORY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+--------+------------------+----------+--------+------+-----+-----+--------------------+\n",
      "|CONGESTION|MIN_n|OSM_ID_n|LARGER_THAN_200M_n|CATEGORY_n|STORES_n|HOUR_n|DAY_n|KMH_n|            features|\n",
      "+----------+-----+--------+------------------+----------+--------+------+-----+-----+--------------------+\n",
      "|         0|  0.0|     0.0|               1.0|       1.0|     1.0|   3.0|  6.0|  1.0|[3.0,0.0,1.0,1.0,...|\n",
      "|         0|  1.0|     0.0|               1.0|       1.0|     0.0|   6.0|  6.0|  1.0|[6.0,1.0,1.0,1.0,...|\n",
      "|         0|  2.0|     0.0|               1.0|       1.0|     1.0|  13.0|  5.0|  1.0|[13.0,2.0,1.0,1.0...|\n",
      "+----------+-----+--------+------------------+----------+--------+------+-----+-----+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "vector_assembler = VectorAssembler(\\\n",
    "inputCols=['HOUR_n','MIN_n','KMH_n','CATEGORY_n','OSM_ID_n','LARGER_THAN_200M_n','STORES_n','DAY_n'],\\\n",
    "outputCol=\"features\")\n",
    "df_temp = vector_assembler.transform(data)\n",
    "df_temp.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+\n",
      "|CONGESTION|            features|\n",
      "+----------+--------------------+\n",
      "|         0|[3.0,0.0,1.0,1.0,...|\n",
      "|         0|[6.0,1.0,1.0,1.0,...|\n",
      "|         0|[13.0,2.0,1.0,1.0...|\n",
      "+----------+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_temp.drop('HOUR_n','MIN_n','KMH_n','CATEGORY_n','OSM_ID_n','LARGER_THAN_200M_n','STORES_n','DAY_n')\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "l_indexer = StringIndexer(inputCol=\"CONGESTION\", outputCol=\"labelIndex\")\n",
    "df = l_indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+----------+\n",
      "|CONGESTION|            features|labelIndex|\n",
      "+----------+--------------------+----------+\n",
      "|         0|[3.0,0.0,1.0,1.0,...|       0.0|\n",
      "|         0|[6.0,1.0,1.0,1.0,...|       0.0|\n",
      "|         0|[13.0,2.0,1.0,1.0...|       0.0|\n",
      "|         0|[10.0,2.0,1.0,1.0...|       0.0|\n",
      "|         0|[5.0,3.0,1.0,1.0,...|       0.0|\n",
      "|         0|[13.0,1.0,1.0,1.0...|       0.0|\n",
      "|         0|[3.0,1.0,1.0,1.0,...|       0.0|\n",
      "|         1|[8.0,1.0,1.0,1.0,...|       1.0|\n",
      "|         1|[1.0,0.0,1.0,1.0,...|       1.0|\n",
      "|         1|[6.0,0.0,1.0,1.0,...|       1.0|\n",
      "|         0|[4.0,1.0,1.0,1.0,...|       0.0|\n",
      "|         0|[4.0,2.0,1.0,1.0,...|       0.0|\n",
      "|         1|[11.0,0.0,1.0,1.0...|       1.0|\n",
      "|         0|[2.0,3.0,1.0,1.0,...|       0.0|\n",
      "|         0|[4.0,2.0,1.0,1.0,...|       0.0|\n",
      "|         0|[8.0,1.0,1.0,1.0,...|       0.0|\n",
      "|         0|[15.0,3.0,1.0,1.0...|       0.0|\n",
      "|         1|[1.0,3.0,1.0,1.0,...|       1.0|\n",
      "|         0|[9.0,0.0,1.0,1.0,...|       0.0|\n",
      "|         0|[9.0,3.0,1.0,1.0,...|       0.0|\n",
      "|         0|[19.0,2.0,1.0,1.0...|       0.0|\n",
      "|         0|[18.0,1.0,1.0,1.0...|       0.0|\n",
      "|         0|[18.0,2.0,1.0,1.0...|       0.0|\n",
      "|         0|[18.0,3.0,1.0,1.0...|       0.0|\n",
      "|         0|[22.0,1.0,1.0,1.0...|       0.0|\n",
      "|         0|[22.0,2.0,1.0,1.0...|       0.0|\n",
      "|         0|[10.0,3.0,1.0,1.0...|       0.0|\n",
      "|         0|[12.0,0.0,1.0,1.0...|       0.0|\n",
      "|         0|[13.0,3.0,1.0,1.0...|       0.0|\n",
      "|         0|[7.0,0.0,1.0,1.0,...|       0.0|\n",
      "|         1|[8.0,0.0,1.0,1.0,...|       1.0|\n",
      "|         1|[0.0,3.0,1.0,1.0,...|       1.0|\n",
      "|         1|[12.0,2.0,1.0,1.0...|       1.0|\n",
      "|         0|[3.0,3.0,1.0,1.0,...|       0.0|\n",
      "|         1|(8,[0,2,3,5],[9.0...|       1.0|\n",
      "|         0|[16.0,1.0,1.0,1.0...|       0.0|\n",
      "|         0|[17.0,1.0,1.0,1.0...|       0.0|\n",
      "|         0|[17.0,0.0,1.0,1.0...|       0.0|\n",
      "|         0|[17.0,2.0,1.0,1.0...|       0.0|\n",
      "|         0|[8.0,2.0,1.0,1.0,...|       0.0|\n",
      "|         0|[0.0,0.0,1.0,1.0,...|       0.0|\n",
      "|         0|[0.0,2.0,1.0,1.0,...|       0.0|\n",
      "|         0|[11.0,0.0,1.0,1.0...|       0.0|\n",
      "|         1|[12.0,1.0,1.0,1.0...|       1.0|\n",
      "|         1|[12.0,0.0,1.0,1.0...|       1.0|\n",
      "|         2|[6.0,3.0,1.0,1.0,...|       2.0|\n",
      "|         2|[9.0,2.0,1.0,1.0,...|       2.0|\n",
      "|         2|[2.0,2.0,1.0,1.0,...|       2.0|\n",
      "|         1|[4.0,2.0,1.0,1.0,...|       1.0|\n",
      "|         1|[19.0,3.0,1.0,1.0...|       1.0|\n",
      "|         0|[18.0,2.0,1.0,1.0...|       0.0|\n",
      "|         0|[18.0,3.0,1.0,1.0...|       0.0|\n",
      "|         0|[23.0,0.0,1.0,1.0...|       0.0|\n",
      "|         1|[0.0,1.0,1.0,1.0,...|       1.0|\n",
      "|         0|[10.0,1.0,1.0,1.0...|       0.0|\n",
      "|         1|[11.0,1.0,1.0,1.0...|       1.0|\n",
      "|         1|[11.0,0.0,1.0,1.0...|       1.0|\n",
      "|         1|[3.0,2.0,1.0,1.0,...|       1.0|\n",
      "|         1|[13.0,1.0,1.0,1.0...|       1.0|\n",
      "|         1|[13.0,2.0,1.0,1.0...|       1.0|\n",
      "|         1|[15.0,1.0,1.0,1.0...|       1.0|\n",
      "|         0|[9.0,1.0,1.0,1.0,...|       0.0|\n",
      "|         0|[9.0,3.0,1.0,1.0,...|       0.0|\n",
      "|         0|[10.0,2.0,1.0,1.0...|       0.0|\n",
      "|         0|[12.0,1.0,1.0,1.0...|       0.0|\n",
      "|         0|[12.0,2.0,1.0,1.0...|       0.0|\n",
      "|         0|[3.0,0.0,1.0,1.0,...|       0.0|\n",
      "|         0|[13.0,2.0,1.0,1.0...|       0.0|\n",
      "|         0|[19.0,1.0,1.0,1.0...|       0.0|\n",
      "|         0|[18.0,1.0,1.0,1.0...|       0.0|\n",
      "|         1|[14.0,0.0,1.0,1.0...|       1.0|\n",
      "|         1|[8.0,1.0,1.0,1.0,...|       1.0|\n",
      "|         0|[10.0,0.0,1.0,1.0...|       0.0|\n",
      "|         1|[10.0,3.0,1.0,1.0...|       1.0|\n",
      "|         0|[11.0,3.0,1.0,1.0...|       0.0|\n",
      "|         0|[12.0,2.0,1.0,1.0...|       0.0|\n",
      "|         0|[5.0,2.0,1.0,1.0,...|       0.0|\n",
      "|         0|[1.0,0.0,1.0,1.0,...|       0.0|\n",
      "|         0|[6.0,0.0,1.0,1.0,...|       0.0|\n",
      "|         0|[18.0,0.0,1.0,1.0...|       0.0|\n",
      "|         0|[23.0,3.0,1.0,1.0...|       0.0|\n",
      "|         0|[14.0,2.0,1.0,1.0...|       0.0|\n",
      "|         1|[7.0,3.0,1.0,1.0,...|       1.0|\n",
      "|         1|[0.0,3.0,1.0,1.0,...|       1.0|\n",
      "|         0|[12.0,0.0,1.0,1.0...|       0.0|\n",
      "|         1|[5.0,1.0,1.0,1.0,...|       1.0|\n",
      "|         0|[6.0,3.0,1.0,1.0,...|       0.0|\n",
      "|         0|[9.0,1.0,1.0,1.0,...|       0.0|\n",
      "|         1|[18.0,1.0,1.0,1.0...|       1.0|\n",
      "|         0|[22.0,1.0,1.0,1.0...|       0.0|\n",
      "|         0|(8,[0,2,3,5],[23....|       0.0|\n",
      "|         0|[23.0,2.0,1.0,1.0...|       0.0|\n",
      "|         1|[17.0,3.0,1.0,1.0...|       1.0|\n",
      "|         1|[10.0,2.0,1.0,1.0...|       1.0|\n",
      "|         1|[11.0,0.0,1.0,1.0...|       1.0|\n",
      "|         1|[11.0,2.0,1.0,1.0...|       1.0|\n",
      "|         0|[13.0,0.0,1.0,1.0...|       0.0|\n",
      "|         0|[13.0,2.0,1.0,1.0...|       0.0|\n",
      "|         1|[15.0,2.0,1.0,1.0...|       1.0|\n",
      "|         1|[1.0,1.0,1.0,1.0,...|       1.0|\n",
      "+----------+--------------------+----------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('CONGESTION')\n",
    "(trainingData, testData) = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(\n",
    "    labelCol=\"labelIndex\", featuresCol=\"features\", impurity='entropy')\n",
    "model = dt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+\n",
      "|prediction|labelIndex|\n",
      "+----------+----------+\n",
      "|       0.0|       1.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       2.0|\n",
      "|       0.0|       0.0|\n",
      "|       0.0|       2.0|\n",
      "+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\", \"labelIndex\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7326968973747017\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"labelIndex\", predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier_5bd31ecf3930__impurity\n"
     ]
    }
   ],
   "source": [
    "print(model.impurity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
